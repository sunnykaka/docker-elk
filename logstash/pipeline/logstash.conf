input {
#  tcp {
#    port => 5000
#  }
  #beats {
  #  port => 10515
  #}
     kafka {
        bootstrap_servers => ["192.168.50.10:9092,192.168.50.11:9092,192.168.50.12:9092"]
        topics_pattern => ["javalog-.*"]
        auto_offset_reset => "latest"
        consumer_threads => 4
        decorate_events => true
        codec => "json"
        fetch_max_bytes => "5242880"
        max_poll_records => "500"
        group_id => "erp-java1"
      }
}


filter {
     ruby {
       code => "
         begin
           event.set('logstash_ts', event.get('@timestamp'))
           rescue Exception => e
             event.set('logstash_ruby_exception', '[logstash_ts]: ' + e.message)
         end
       "
     }

     json{
        source => "message"
     }
     json{
        source => "traceMessage"
        target => "trace"
        remove_field => [ "traceMessage","message" ]
     }
     ruby {
       code => "
         begin
           event.set('logstash_ts2', Time.new.strftime('%Y-%m-%d %H:%M:%S'))
         end
       "
     }

}


#filter {
#     json{
#        source => "message"
#     }
#     json{
#        source => "traceMessage"
#        target => "trace"
#        remove_field => [ "traceMessage","message" ]
#     }
#}


#filter {
#    if "beats_input_codec_plain_applied" in [tags] {
#        mutate {
#            remove_tag => ["beats_input_codec_plain_applied"]
#        }
#    }
#}


output {
        elasticsearch {
                hosts => "elasticsearch:9200"
                user => "elastic"
                password => "changeme"
                #index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
                index => "javalog10-%{+YYYY.MM.dd}"
        }
}
